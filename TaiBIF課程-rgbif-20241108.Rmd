---
title: "TaBIF課程-rgbif-20241108"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

# 生物多樣性資料應用課程 - 使用 `rgbif` 套件

##### tags: `資料應用` `資料清理` `API` `GBIF` `TaiBIF` `TBIA`

</br >

### 📒 此教材來自 2024/11 所舉辦的「[TaiBIF](https://portal.taibif.tw/) 生物多樣性資料應用工作坊」
#### **Created by:** 何芷蔚 [Daphne Hoh](https://orcid.org/0000-0002-7810-1034), 吳俊毅 Junyi Wu
#### **Created:** 2024-09-02
#### **Last modified:** 2024-10-30

</br >

## 🚩 課程目標
#### 1. 學會怎麼用 R 套件 [*`rgbif`*](https://docs.ropensci.org/rgbif/) 下載 GBIF 資料
#### 2. 學會怎麼用 TBIA API 下載 TBIA 資料
#### 3. 了解 GBIF 與 TBIA 所下載的資料可能會出現的品質問題 (potential data quality issue)
#### 4. 畫出物種出現紀錄分布圖
#### 5. 如何引用所下載的資料


</br >

## 🪄 課前準備
#### 1. 此 HTML 文件[連結](https://drive.google.com/file/d/1TrJgT5ksexdpoEraVJzZh3HIzGGJrTpc/view?usp=drive_link)
#### 2. 學員文件夾[連結](https://drive.google.com/drive/folders/1MQ5c3dWajjJdp5LBPwkFjvi-ENKY-8jV?usp=drive_link)
#### 3. 這次課堂裡所使用的工具版本：
  + R 版本：4.4.1
  + *`rgbif`* 版本：3.8.1


</br >

##  💻 環境準備
```{r, message = F}
# 雙引號之間的文字要改為自己的檔案路徑
setwd("/Users/taibif/Desktop/202411_rgbif") # Mac
setwd("C:/Users/taibif/Desktop/202411_rgbif") # Window

.packs <- c("rgbif", "data.table", "arrow", "ggplot2",
            "devtools", "tidyverse", "CoordinateCleaner", 
            "rnaturalearth", "sf", "ggmap", "jsonlite", 
            "progressr", "lubridate", "raster")
```


```{r, message = F}
#install.packages(.packs)
sapply(.packs, require, character.only = T)

# 下列套件需要使用 devtools 來裝 
devtools::install_github("ropensci/rnaturalearthhires")
library(rnaturalearthhires)

# 跑出此 Rmd 教材的電腦與 R 環境設定
sessionInfo()
```

</br >

## (1) 🔍 使用 rgbif 套件來下載 GBIF 的資料
### 1.1 - 找出物種的 taxonKey
#### 這次的課堂範例，我們來看臺灣的原生物種—黑冠麻鷺 *Gorsachius melanolophus*
```{r}
# 方法（一）：到 GBIF 網站找 https://www.gbif.org/species/"XXXXXXX"
taxonKey <- 2480841

# 方法（二）：
name_backbone(name = "Gorsachius melanolophus", rank = "species") %>% 
  data.frame()
```
#### + 注意 `status` 欄位檢查輸入的學名是否有效
#### + 注意 `matchType` 欄位檢查輸入的學名是否為你要找的物種或是否拼錯
#### + 範例參考：
####    + name_backbone(name = "Magnoliophyta") # `status` 是 'Synonym' (同物異名)
####    + name_backbone(name = "Aegithalos caudatus") # `status` 是 'Doubtful' (有疑慮的)
```{r}
# 上面檢查沒問題後，存入 taxonKey
taxonKey <- name_backbone(name = "Gorsachius melanolophus", rank = "species") %>% 
  pull(usageKey)
```

</br >

### 1.2 - 針對 taxonKey 下載出現紀錄
```{r, message = F}
# 要登入 GBIF 帳號才能下載資料
gbif_download_key <- occ_download(pred("taxonKey", taxonKey), # 下載此 taxonKey 的出現紀錄
                                  format = "SIMPLE_CSV",
                                  user = "yourName", # 輸入你的 GBIF User ID
                                  pwd = "yourPW", # 密碼
                                  email = "yourEmail@gmail.com") # 用來註冊 GBIF 帳號的 email

# 查看下載狀態
# 如果資料很多，會需要等一陣子
occ_download_wait(gbif_download_key)

# 直接讀進 R 成 data frame
# 也另存一個壓縮檔到本機路徑
gbif_download <- occ_download_get(gbif_download_key, overwrite = T) %>% 
  occ_download_import()

head(gbif_download, 5) 
colnames(gbif_download) # 看看有什麼欄位
```
#### + 看各欄位代表什麼：Darwin Core (DwC) Terms https://dwc.tdwg.org/list/
#### + 完整的 DwC Terms 有超過 350 個
#### + rgbif 的 occ_download_get 共有 50 個
#### + 有一些欄位例如：gbifID, lastInterpreted, mediaType, issue 等是 GBIF 詮釋資料，不是 DwC

</br >

## (2) 🔍 使用 TBIA API 來下載 TBIA 的資料
### 2.1 - 找出物種的 taxonID
#### 我們來看臺灣的原生物種—黑冠麻鷺 *Gorsachius melanolophus*
```{r}
# 到 TaiCOL 網站找 https://taicol.tw/zh-hant/taxon/"txxxxxxx"
taxonID <- "t0064796"

# 用 TaiCOL API 檢查物種資訊：
splist <- fromJSON(sprintf("https://api.taicol.tw/v2/taxon?taxon_id=%s", taxonID))
splist$data
```
#### + 注意 `taxon_status` 欄位檢查輸入的學名是否有效
#### + 範例參考： taxonID <- "t0082561" # `taxon_status` 是 'Delete' (無效名)

</br >

### 2.2 - 針對 taxonID 下載出現紀錄
#### TBIA API 說明文件 https://tbiadata.tw/zh-hant/api/doc
```{r, message = F}
# 使用 TBIA API 的 taxonID 查詢參數下載 TBIA 觀測紀錄:
# 1. 初始 API 呼叫，下載第一頁資料
initial_url <- sprintf("https://tbiadata.tw/api/v1/occurrence?taxonID=%s&isCollection=false&limit=1000", taxonID)
occurrence <- fromJSON(initial_url)
all_data <- list()  # 初始化列表來儲存所有頁面的資料
all_data[[1]] <- occurrence$data

# 2. 計算總頁數
pg <- floor(occurrence$meta$total / 1000)
if (occurrence$meta$total %% 1000 == 0) {  # 修正比較為數值 0
  pg <- pg - 1  # 避免頁數剛好整除導致後面迴圈出錯
}

# 3. 使用 progressr 的 with_progress 來顯示進度條
with_progress({
  p <- progressor(along = 1:pg)
  
  for(j in 1:pg){
    success <- FALSE
    while(!success) {
      TT_API <- tryCatch({
        # 使用下一頁的連結進行 API 呼叫
        occurrence <- fromJSON(occurrence$links$`next`)
        # 檢查 occurrence$data 是否為空
        if(length(occurrence$data) == 0){
          message(sprintf("Page %d has no data. Skipping.", j))
        } else {
          # 將當前頁的資料添加到列表
          all_data[[j + 1]] <- occurrence$data
        }
        success <- TRUE
      }, error = function(e) {
        message("Error occurred: ", e$message)
        message("Retrying after 5 seconds")
        Sys.sleep(5)  # 延遲 5 秒後重試
        return(NULL)
      })
    }
    
    # 更新進度條
    p(sprintf("Downloaded page %d", j))
  }
})

# 4. 合併所有資料到一個 data.table
TBIA_download <- rbindlist(all_data, fill = TRUE) %>% 
  as.data.frame( )

# 5. 確認合併後的資料結構
head(TBIA_download, 5) 
colnames(TBIA_download) # 看看有什麼欄位
```
#### + 使用 API 請先根據想下載的目標挑選使用的參數
#### + 注意 API 共同參數與連結 API 會取得得資料架構
#### + 檢查 API 回傳欄位以及格式是否都符合 API 說明文件

</br >


## (3)️ 🧭 GBI F資料與 TBIA 資料合併
```{r, message = F}
#### 挑選 GBIF 資料與 TBIA 資料的共通欄位
#### 新增一個欄位確認這些資料來自 GBIF
GBIF_download_filter <- gbif_download %>%
  dplyr::select(., basisOfRecord, establishmentMeans, decimalLatitude, decimalLongitude, 
                eventDate, year, month, day, elevation, countryCode, coordinateUncertaintyInMeters, species) %>% 
  mutate(from = "GBIF")

#### 挑選 TBIA 資料與 GBIF 資料的共通欄位
#### 新增一個欄位確認這些資料來自 TBIA
TBIA_download_filter <- TBIA_download %>%
  dplyr::select(., basisOfRecord, standardLatitude, standardLongitude, 
                standardDate, coordinateUncertaintyInMeters, scientificName) %>% 
  setnames(., c("standardLatitude", "standardLongitude", "standardDate", "scientificName"), 
           c("decimalLatitude", "decimalLongitude", "eventDate", "species")) %>%
  mutate(year = year(eventDate),
    month = month(eventDate),
    day = day(eventDate), 
    from = "TBIA")

combine_table <- rbindlist(list(GBIF_download_filter, TBIA_download_filter), fill = TRUE)

#### 確認欄位的資料格式差異
# combine_table$year %>% table() %>% 
#   as.character()
# combine_table$coordinateUncertaintyInMeters %>% table() %>% 
#   as.character()


# 使用正則表達式找出非數字的值
non_numeric_entries <- combine_table %>%
  filter(!grepl("^\\d+(\\.\\d+)?$", coordinateUncertaintyInMeters))
# 正則表達式解釋：
# ^ 和 $ 分別表示行的開始和結束，確保整個字串都符合數字格式。
# \\d+ 表示一個或多個數字。
# (\\.\\d+)? 表示可選的小數點後面跟著一個或多個數字。

# 查看這些記錄
non_numeric_entries$coordinateUncertaintyInMeters %>% table()


combine_table_ver2 <- combine_table %>% 
  mutate(
    coordinateUncertaintyInMeters = case_when(
      coordinateUncertaintyInMeters == "<25公尺" ~ "25",
      coordinateUncertaintyInMeters == "100-500" ~ "500",
      coordinateUncertaintyInMeters == "1e+06" ~ "1000000",
      TRUE ~ coordinateUncertaintyInMeters  # 保留其他值不變
    )
  ) %>% 
  mutate(
    coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters),  # 轉換為數值型
    year = as.character(year)  # 確保 year 是字符型
  )

# 我們只是想繪製分布圖
# 如果有過多重複資料可以先排除掉
combine_table_final <- combine_table_ver2 %>%
  distinct(decimalLatitude, decimalLongitude, .keep_all = TRUE)


fwrite(combine_table_final, "combine_table_final.csv")
```
#### + 要合併兩個不同來源的公開資料請確認共同欄位
#### + 檢查共同欄位格式與資料內容
#### + 合併之後可根據目的做資料篩選與排除

</br >

## (4)️ 🧭 資料點位視覺化
#### 黑冠麻鷺 *Gorsachius melanolophus* ，我們先來看一下資料在地圖上的分布
```{r, message = F}
# 環境內變數太多，我們先把東西都清除
rm(list=ls())

world.map <- ne_countries(returnclass = "sf") # 下載世界地圖

combine_table_final<- read_delim_arrow("combine_table_final.csv", delim = ",")

# 下載的資料在世界的分布
ggplot() +
  geom_sf(data = world.map) +
  geom_point(data = combine_table_final,
             aes(x = decimalLongitude, # 經度
                 y = decimalLatitude), # 緯度
             shape = "+",
             color = "red") +
  theme_bw()
```
```{r, message = F}
tw.map <- ne_countries(country = "Taiwan", scale = "large", returnclass = "sf") # 下載臺灣地圖

# 下載的資料在臺灣的分布
ggplot() +
  geom_point(data = combine_table_final,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +
  geom_sf(data = tw.map) + 
  theme_bw()
# 繪製出來的地圖，很明顯的資料分布有大量都不再臺灣本島內
```
#### 黑冠麻鷺是東南亞都會分布的物種，但我們只需要台灣範圍內的資料
#### 我們來看看該怎麼針對這樣的資料做清理

</br >

## (4) 🚧 資料清理
#### ⚠️ 注意 ⚠️ 清理資料的步驟沒有統一的作法
#### 所有清理步驟都會以你的研究目的與要做的分析方式做調整
#### 此教材裡提到的清理步驟是 GBIF 加上 TBIA 建議可以注意的地方

</br >

### 4.1 - 我只想要原生 & 野生的出現紀錄，去除典藏資料！
```{r, message = F}
table(combine_table_final$basisOfRecord) # basisOfRecord = 資料類型
table(combine_table_final$establishmentMeans) # establishmentMeans = 原生狀態。
# 黑冠麻鷺資料沒有出現其他外來種資訊，我們可以先預設他們都是原生資料。

clean.step.1 <- combine_table_final %>%
  filter(!basisOfRecord %in% c("FOSSIL_SPECIMEN", "LIVING_SPECIMEN", "PRESERVED_SPECIMEN", "MATERIAL_CITATION")) %>% 
  filter(!establishmentMeans %in% c("MANAGED", "INTRODUCED", "INVASIVE", "NATURALISED"))

print(paste0(nrow(combine_table_final) - nrow(clean.step.1), " records deleted; ",
             nrow(clean.step.1), " records remaining."))


# 來看一下資料清除前與後的地理分布
ggplot() +
  geom_sf(data = world.map) +
  geom_point(data = combine_table_final,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "blue") +  # 被移除的資料
  geom_point(data = clean.step.1,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +  # 保留下來的資料
  theme_bw()
```

</br >

### 4.2 - 把一些有明顯地理錯誤的資料去除
#### 使用方便的 *`CoordinateCleaner`* 套件
```{r}
# 以下註解分別為清理的部分
clean.step.2 <- clean.step.1 %>% 
  filter(!is.na(decimalLatitude), !is.na(decimalLongitude), # 無經緯度資訊
         countryCode == "TW") %>% # 保留在台灣的點位
  cc_dupl() %>% # 經緯度點位重複
  cc_zero() %>% # 經緯度為 0
  cc_equ() %>% # 經緯度為同數值
  cc_val() %>% # 經緯度無效 (緯度 > 90 & < -90; 經度 > 180 & < -180)
  cc_sea() %>% # 海上
  cc_cen(buffer = 5) # 國家的中間點，數字單位是公里

print(paste0(nrow(clean.step.1) - nrow(clean.step.2), " records deleted; ",
             nrow(clean.step.2), " records remaining."))  
```
```{r, message = F}
# 來看一下資料清除前與後的地理分布
ggplot() +
  geom_sf(data = world.map) +
  geom_point(data = clean.step.1,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "blue") +  # 被移除的資料
  geom_point(data = clean.step.2,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +  # 保留下來的資料
  theme_bw()
```

#### 移除成功！我們接下來看台灣的資料就好
```{r, message = F}
ggplot() +
  geom_sf(data = tw.map) +
  geom_point(data = clean.step.2,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +
  theme_bw()
```

</br >

### 4.3 - 移除座標不確定性很高的資料
#### 如果物種的實際點位對接下來要做的分析很重要
#### 比如說：用來跑物種分布模型
#### 那必須針對 coordinateUncertaintyInMeters (座標不確定性) 欄位做適當的清理
```{r}
table(clean.step.2$coordinateUncertaintyInMeters)

clean.step.3 <- clean.step.2 %>% 
  filter(!is.na(coordinateUncertaintyInMeters) |  # 移除空值
           coordinateUncertaintyInMeters < 1000)  # 保留 < 1000 公尺以下的

print(paste0(nrow(clean.step.2) - nrow(clean.step.3), " records deleted; ",
             nrow(clean.step.3), " records remaining." ))  

ggplot() +
  geom_sf(data = tw.map) +
  geom_point(data = clean.step.3,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +
  theme_bw()
```

</br >

### 4.4 - 移除海拔過高的資料
#### 黑冠麻鷺的海拔平均分布大概位於 1000 以下
```{r}
ele_raster <- raster("C:/Users/taibi/OneDrive/Desktop/202411_rgbif/input/polygon/twdtm_asterV2_30m.tif")
clean.step.3_sf<- clean.step.3 %>%
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), remove=FALSE) %>% # set coordinates
  st_set_crs(4326)

clean.step.3_sf$elevation <- extract(ele_raster, clean.step.3_sf)
clean.step.4 <- clean.step.3_sf %>% 
  st_drop_geometry(.) %>% 
  filter(!(elevation>1000))
  
ggplot() +
  geom_sf(data = tw.map) +
  geom_point(data = clean.step.4,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +
  theme_bw()

print(paste0(nrow(clean.step.3) - nrow(clean.step.4), " records deleted; ",
             nrow(clean.step.4), " records remaining." )) 
```

</br >

### 4.5 - 我對很舊或無年份的紀錄有疑慮，移除！
#### 在 GBIF 裡，很舊的紀錄通常是標本
```{r}
# 視情況自己定義該保留什麼年份
table(clean.step.4$year)

clean.step.5 <- clean.step.4 %>% 
  filter(year > 1980 & year < 2025) # 有些資料也會出現“未來”年份，移除
```

</br >

### 4.6 - 最後檢視到底被移除多少有疑慮的資料
```{r, message = F}
ggplot() +
  geom_sf(data = tw.map) +
  geom_point(data = combine_table_final,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "blue") +  # 所有被移除的資料
  geom_point(data = clean.step.5,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +  # 清理後，保留下來的資料
  theme_bw() +
  coord_sf(xlim = st_bbox(tw.map)[c(1,3)],
           ylim = st_bbox(tw.map)[c(2,4)])
```

### 4.7 - 清理後，剩下的資料
```{r}
ggplot() +
  geom_sf(data = tw.map) +
  geom_point(data = clean.step.5,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             shape = "+",
             color = "red") +
  theme_bw()
```

#### 清理後能用的資料從剛開始的 25,244 筆到只剩 4890 筆 (操作時間：10/30) 
#### 當然也可能是因為對資料品質的要求太嚴格了
#### 再視情況自己調整啦～ 

</br >

## (5) 🗺 來個圖層 + 網格教學
### 下載 GBIF 特定範圍的物種出現紀錄
```{r}
location <- "POLYGON((121.61304 25.04929, 121.61085 25.0495, 121.60583 25.04833, 121.60672 25.04555, 121.60627 25.04138, 121.60915 25.03876, 121.61668 25.03708, 121.61675 25.03795, 121.61759 25.03972, 121.61724 25.04091, 121.61682 25.04208, 121.61624 25.04317, 121.61507 25.04574, 121.61554 25.0474, 121.61563 25.0488, 121.61304 25.04929))"


# 另一種更快速篩選、選擇特定範圍與下載 GBIF 資料的方法
taxonKey <- 2480841
gbif_download_key <- occ_download(pred("taxonKey", taxonKey),
                                  pred_within(location),
                                  pred_or(pred_lt("coordinateUncertaintyInMeters", 1000),
                                          pred_notnull("coordinateUncertaintyInMeters")),
                                  format = "SIMPLE_CSV",
                                  user = "yourID", # 輸入你的 GBIF User ID
                                  pwd = "yourPW", # 密碼
                                  email = "yourEmail@gmail.com") # 用來註冊 GBIF 帳號的 email

# 下載並解壓縮
gbif_download_metadata <- occ_download_wait(gbif_download_key)
gbif_download_path <- "./gbif_download.zip" # 指定下載檔案的路徑
download.file(gbif_download_metadata$downloadLink, gbif_download_path) # 下載到本機
unzip(gbif_download_path) # 在本機壓縮下載檔

GBIF_data <- fread(sprintf("%s.csv", gbif_download_metadata$key), 
                   sep = "\t", fill = T, encoding = "UTF-8", colClasses = "character", quote = "")


# 將 WKT 轉換為 sf object
sfc <- st_as_sfc(location)
polygon_sf <- st_sf(geometry = sfc)

# 劃多邊形 (這是 WGS84)
ggplot() +
  geom_sf(data = polygon_sf,
          color = "black", size = 0.2, inherit.aes = F, alpha = 0.3)

# 設定原始坐標系統 (先告訴 R 預設圖層是是 WGS84, EPSG:4326)
st_crs(polygon_sf) <- 4326

# 要轉換到 TWD97 (EPSG:3826)。繪製網格必須要讓坐標系統轉換成二度分帶才精準
polygon_sf_twd97 <- st_transform(polygon_sf, 3826)

# 創建 100m x 100m 的網格
grid <- st_make_grid(polygon_sf_twd97, cellsize = c(100, 100)) %>% 
  st_as_sf()

# 畫出 grid
ggplot() +
  geom_sf(data = grid,
          color = "black", size = 0.2, inherit.aes = F, alpha = 0.3)

# 用產生的 Polygon 挑選網格
intersects_result <- st_intersects(grid, polygon_sf_twd97)
selected_grids <- grid[unlist(lapply(intersects_result, length)) > 0, ]

# 畫出篩選 grid 與多邊形重疊圖
ggplot() +
  geom_sf(data = selected_grids, fill = "red", alpha = 0.5) + # 繪製 selected_grids
  geom_sf(data = polygon_sf_twd97, fill = "lightblue") + # 繪製 polygon_sf_twd97
  theme_minimal()


# 將 GBIF_data 根據座標轉成 Point polygon，因座標本身是WGS84，故投影成WGS84
GBIF_sf <- st_as_sf(GBIF_data, coords = c("decimalLongitude", "decimalLatitude"), crs = 4326)

# 畫出 GBIF 點位圖
ggplot() +
  geom_sf(data = GBIF_sf)


# 畫出 GBIF 點位以及篩選 grid 重疊圖
ggplot() +
  geom_sf(data = selected_grids, fill = "red", alpha = 0.5) + # 繪製 selected_grids
  geom_sf(data = GBIF_sf)+
  theme_minimal()


# 因為 GBIF 的資料的座標系統原本都是 WGS84，將點位圖層轉成 TWD97
GBIF_sf_TWD97 <- st_transform(GBIF_sf, crs = 3826)

# 產生邏輯矩陣，判斷兩個圖層有多少資料有交集
points_per_grid <- st_intersects(GBIF_sf_TWD97, selected_grids, sparse = F)

# 將邏輯舉證轉換成數列，計算每個網格有多少點位數量
count_points <- apply(points_per_grid, 2, sum)
selected_grids$count <- count_points

# 繪製熱點圖
ggplot(data = selected_grids) +
  geom_sf(aes(fill = count), color = "black", size = 0.2) +
  scale_fill_gradientn(colors = c("white", "blue", "red"), 
                       values = scales::rescale(c(0, 1, max(selected_grids$count, na.rm = T))),
                       na.value = "white", 
                       name = "Count") +
  theme_minimal() +
  labs(title = "Selected Grids based on Count", x = "Longitude", y = "Latitude")

# 將完成的網格輸出成 shapefile，可以在 GIS 軟體上操作編輯
#st_write(selected_grids, "RGBIF_result.shp")
```

</br >


## (6) 🌞 引用方法
```{r}
gbif_download_key

print(gbif_citation(occ_download_meta(gbif_download_key))$download)
```

</br >

### 🐒 其他
#### 如果想試別的物種資料：
```{r}
#name_backbone(name = "Macaca cyclopis", rank = "species") # 臺灣獼猴
#name_backbone(name = "Odorrana swinhoana", rank = "species") # 斯文豪氏蛙
#name_backbone(name = "Yuhina brunneiceps", rank = "species") # 冠羽畫眉
#name_backbone(name = "Alpinia uraiensis", rank = "species") # 烏來月桃
```

</br >

### 📚 延伸閱讀
1. GBIF interpreted data - [Issues and Flags](https://data-blog.gbif.org/post/issues-and-flags/) 
2. List of [Darwin Core Term](https://dwc.tdwg.org/list/)
3. Data blog - [GBIF API beginners guide](https://data-blog.gbif.org/post/gbif-api-beginners-guide/)
4. Data blog - [GBIF Species API](https://data-blog.gbif.org/post/gbif-species-api/)
5. GBIF 出版文件 - [資料品質原則](https://www.gbif.org/document/80509/principles-of-data-quality) ([英](https://assets.ctfassets.net/uo17ejk9rkwj/2gupj7dJIw62UeOUYiqSsm/0a4bb732bd7fd8cf28f7703dc20a43ba/Data_Quality_-_ENGLISH.pdf)/[中譯](https://assets.ctfassets.net/uo17ejk9rkwj/3IabOUm6FWoikQKceYIQ8g/59fa78644598800faa096c157ce36b03/Principles_20of_20Data_20Quality_20-_20Chinese.pdf))
6. GBIF 出版文件 - [原始物種與物種出現紀錄資料](https://www.gbif.org/document/80528/principles-and-methods-of-data-cleaning-primary-species-and-species-occurrence-data)
7. [TBIA API 説明文件](https://tbiadata.tw/zh-hant/api/doc)

</br >

### 💡 參考
1. **Main reference for this course material / Modified from:** GBIF Secretariat (2021) GBIF Biodiversity Data Use Course. 6th edition. GBIF Secretariat: Copenhagen. https://doi.org/10.15468/ce-wkk4-2w26. 

2. Chamberlain S, Barve V, Mcglinn D, Oldoni D, Desmet P, Geffert L, Ram K (2023). rgbif: Interface to the Global Biodiversity Information Facility API. R package version 3.7.7.6, https://CRAN.R-project.org/package=rgbif.

</br >

***
> This document is part of a course materials developed for [TaiBIF](https://portal.taibif.tw/) Data Use Workshop (2024-11-08).

